{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyWFTyT5x0Uj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cF76ZtvEyJLL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7u8V2vbFyQw6"
      },
      "outputs": [],
      "source": [
        "def load_data(path, split=0.1):\n",
        "  images = sorted(glob(os.path.join(path, \"images/*\" )))\n",
        "  masks = sorted(glob(os.path.join(path, \"masks/*\" )))\n",
        "\n",
        "  total_size = len(images)\n",
        "  valid_size = int(split * total_size)\n",
        "  test_size = int(split * total_size)\n",
        "\n",
        "  #print(total_size, valid_size, test_size)\n",
        "\n",
        "  train_x, valid_x = train_test_split(images, test_size = valid_size, random_state = 42)\n",
        "  train_y, valid_y = train_test_split(masks, test_size = valid_size, random_state = 42)\n",
        "\n",
        "  train_x, test_x = train_test_split(train_x, test_size = test_size, random_state = 42)\n",
        "  train_y, test_y = train_test_split(train_y, test_size = test_size, random_state = 42)\n",
        "\n",
        "  return(train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
        "\n",
        "def read_image(path):\n",
        "  path = path.decode()\n",
        "  x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "  x = cv2.resize(x, (256,256))\n",
        "  x = x/255.0    \n",
        "  return x\n",
        "\n",
        "def read_mask(path):\n",
        "  path = path.decode()\n",
        "  x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "  x = cv2.resize(x, (256,256))\n",
        "  x = x/255.0\n",
        "  x = np.expand_dims(x, axis = -1)    \n",
        "  return x\n",
        "\n",
        "def tf_parse(x, y):\n",
        "  def _parse(x, y):\n",
        "    x = read_image(x)\n",
        "    y = read_mask(y)\n",
        "    return x, y\n",
        "\n",
        "  x, y = tf.numpy_function(_parse, [x, y], [tf.float64, tf.float64])\n",
        "  x.set_shape([256, 256, 3])\n",
        "  y.set_shape([256, 256, 1])\n",
        "\n",
        "  return x, y\n",
        "\n",
        "def tf_dataset(x, y, batch=8):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "  dataset = dataset.map(tf_parse)\n",
        "  dataset = dataset.batch(batch)\n",
        "  dataset = dataset.repeat()\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdxypvMayTQj"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/Polyp Work/Dataset\"\n",
        "(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(path)\n",
        "print(len(train_x), len(valid_x), len(test_x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGij2T21yYta"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, BatchNormalization, Activation, Conv2DTranspose, Add\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def conv_block(inputs, n_filters, kernel_size=3, strides=1):\n",
        "    x = Conv2D(n_filters, kernel_size, strides=strides, padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def residual_block(inputs, n_filters):\n",
        "    x = conv_block(inputs, n_filters)\n",
        "    x = conv_block(x, n_filters)\n",
        "    x = Add()([x, inputs])\n",
        "    return x\n",
        "\n",
        "def upconv_block(inputs, n_filters, kernel_size=3, strides=2):\n",
        "    x = Conv2DTranspose(n_filters, kernel_size, strides=strides, padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def ResUnetPlusPlus():\n",
        "    input_shape=(256, 256, 3)\n",
        "    inputs = Input(input_shape)\n",
        "    n_classes=1\n",
        "    start_filters=32 \n",
        "    depth=4\n",
        "\n",
        "    skip_connections = []\n",
        "    x = inputs\n",
        "\n",
        "    # Encoder\n",
        "    for i in range(depth):\n",
        "        x = conv_block(x, start_filters * 2 ** i, kernel_size=3, strides=1)\n",
        "        x = residual_block(x, start_filters * 2 ** i)\n",
        "        skip_connections.append(x)\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, start_filters * 2 ** depth, kernel_size=3, strides=1)\n",
        "\n",
        "    # Decoder\n",
        "    for i in reversed(range(depth)):\n",
        "        x = upconv_block(x, start_filters * 2 ** i, kernel_size=3, strides=2)\n",
        "        x = concatenate([x, skip_connections[i]])\n",
        "        x = conv_block(x, start_filters * 2 ** i, kernel_size=3, strides=1)\n",
        "        x = residual_block(x, start_filters * 2 ** i)\n",
        "\n",
        "    # Output\n",
        "    outputs = Conv2D(n_classes, kernel_size=1, strides=1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnRA7SMk1IqG"
      },
      "outputs": [],
      "source": [
        "model = ResUnetPlusPlus()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3WmrBY81tbE"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard\n",
        "from tensorflow.keras.metrics import Recall, Precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QO4bpFUG15-h"
      },
      "outputs": [],
      "source": [
        "def iou(y_true, y_pred):\n",
        "  def f(y_true, y_pred):\n",
        "    intersection = (y_true * y_pred).sum()\n",
        "    union = y_true.sum() + y_pred.sum() - intersection\n",
        "    x = (intersection + 1e-15) / (union + 1e-15)\n",
        "    x = x.astype(np.float32)\n",
        "    return x\n",
        "  return tf.numpy_function(f, [y_true, y_pred], tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v63jm5d718q5"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "batch = 8\n",
        "lr = 1e-4\n",
        "epochs = 100\n",
        "\n",
        "train_dataset = tf_dataset(train_x, train_y, batch = batch)\n",
        "valid_dataset = tf_dataset(valid_x, valid_y, batch = batch)\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(lr)\n",
        "metrics = [\"acc\", Recall(), Precision(), iou]\n",
        "model.compile(loss = \"binary_crossentropy\", optimizer = opt, metrics = metrics)\n",
        "\n",
        "callbacks = [ ModelCheckpoint(\"/content/drive/MyDrive/Polyp Work/2_ResUNet++.hdf5\"),\n",
        "    ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.1, patience = 3),\n",
        "    TensorBoard(),\n",
        "    EarlyStopping(monitor = \"val_loss\", patience = 5, restore_best_weights = False)\n",
        "]\n",
        "\n",
        "\n",
        "train_steps = len(train_x) // batch\n",
        "valid_steps = len(valid_x) // batch\n",
        "\n",
        "if len(train_x) % batch !=0:\n",
        "    train_steps += 1\n",
        "\n",
        "if len(valid_x) % batch !=0:\n",
        "    valid_steps += 1\n",
        "  \n",
        "history = model.fit(\n",
        "    train_dataset, \n",
        "    validation_data = valid_dataset,\n",
        "    epochs = epochs,\n",
        "    steps_per_epoch = train_steps,\n",
        "    validation_steps = valid_steps,\n",
        "    callbacks = callbacks,\n",
        "    shuffle = False\n",
        "  )\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GSrPzBN9cx-"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/drive/MyDrive/Polyp Work/2_ResUNet++.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UenfLj_V9h6m"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdqSgfVx92qO",
        "outputId": "07682d85-04b8-44fc-883b-63248110f616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.9927931427955627\n",
            "Training loss: 0.008807224221527576\n"
          ]
        }
      ],
      "source": [
        "acc = history.history['acc'][-1]\n",
        "loss = history.history['loss'][-1]\n",
        "print('Training Accuracy:',acc);\n",
        "print('Training loss:',loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gw60IIuM97D2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import CustomObjectScope\n",
        "\n",
        "test_dataset = tf_dataset(test_x, test_y, batch = batch)\n",
        "test_steps = len(test_x)//batch\n",
        "if len(test_x) % batch != 0:\n",
        "    test_steps += 1\n",
        "\n",
        "with CustomObjectScope({'iou': iou}):\n",
        "  model = tf.keras.models.load_model(\"/content/drive/MyDrive/Polyp Work/2_ResUNet++.hdf5\")\n",
        "\n",
        "model.evaluate(test_dataset, steps = test_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8la2C-fV-M4u"
      },
      "outputs": [],
      "source": [
        "def read_image(path):\n",
        "  x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "  y = cv2.cvtColor(x, cv2.COLOR_RGB2BGR)\n",
        "  y = cv2.resize(y, (256,256))\n",
        "  y = y/255.0\n",
        "  x = cv2.resize(x, (256,256))\n",
        "  x = x/255.0    #(256, 256, 3)\n",
        "  return x, y\n",
        "\n",
        "def read_mask(path):\n",
        "  x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "  x = cv2.resize(x, (256,256))\n",
        "  x = np.expand_dims(x, axis = -1)    #(256, 256, 1)\n",
        "  return x\n",
        "\n",
        "def mask_parse(mask):\n",
        "    mask = np.squeeze(mask)\n",
        "    mask = [mask, mask, mask]\n",
        "    mask = np.transpose(mask, (1, 2, 0))\n",
        "    return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wm-sqM7N-OHe"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuZXlgkr-Q6e"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "for i, (x, y) in tqdm(enumerate(zip(test_x, test_y)), total = len(test_x)):\n",
        "        x, rgb_img = read_image(x)\n",
        "        y = read_mask(y)\n",
        "                \n",
        "        y_pred = model.predict(np.expand_dims(x, axis = 0))\n",
        "        y_pred = y_pred[0] > 0.5\n",
        "        h, w, _ = x.shape\n",
        "        \n",
        "        #x = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "        white_line = np.ones((h, 10, 3)) * 255.0\n",
        "        \n",
        "        all_images = [\n",
        "            rgb_img, white_line, \n",
        "            mask_parse(y), white_line,\n",
        "            mask_parse(y_pred) * 255.0\n",
        "        ]\n",
        "        \n",
        "        image = np.concatenate(all_images, axis = 1)\n",
        "        \n",
        "        plt.imshow(image)\n",
        "        plt.show()\n",
        "        cv2.imwrite(f\"/content/drive/MyDrive/Polyp_Work/Result_ResUNet++/{i}.png\", image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdV5F7c6-xim",
        "outputId": "294ace9d-8ff6-4874-9975-4e867b3f5a13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keract\n",
            "  Downloading keract-4.5.1-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: keract\n",
            "Successfully installed keract-4.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install keract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CReSzIxg-16u"
      },
      "outputs": [],
      "source": [
        "img_path = '/content/drive/MyDrive/Polyp_Work/CVC-ClinicDB/images/1.png'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRJ4Desh-492"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def preprocess_image(img_path, target_size):\n",
        "    img = Image.open(img_path)\n",
        "    img = img.resize(target_size)\n",
        "    x = np.array(img)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFgeKfds-7zO"
      },
      "outputs": [],
      "source": [
        "from keract import get_activations\n",
        "x = np.expand_dims(x, axis=0)\n",
        "#x = np.squeeze(x, axis=0)\n",
        "activations = get_activations(model, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEYv8bPF-_Q1"
      },
      "outputs": [],
      "source": [
        "from keract import display_activations\n",
        "display_activations(activations, save=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "import numpy\n",
        "\n",
        "with CustomObjectScope({'iou': iou}):\n",
        "  model = tf.keras.models.load_model(\"/content/drive/MyDrive/Polyp_Work/Res_UNet++.hdf5\")\n",
        "\n",
        "#img = plt.imread('/content/drive/MyDrive/Polyp_Work/CVC-ClinicDB/images/1.png')"
      ],
      "metadata": {
        "id": "_CsKrDz2AlXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_layer = model.get_layer('conv2d_25').output\n",
        "heatmap_model = keras.models.Model(inputs=model.input, outputs=last_layer)"
      ],
      "metadata": {
        "id": "6H7uTn5dA5Fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "img = cv2.imread('/content/drive/MyDrive/Polyp_Work/CVC-ClinicDB/images/488.png')\n",
        "img = cv2.resize(img, (256, 256))\n",
        "img = np.expand_dims(img, axis=0)\n",
        "\n",
        "heatmap_activations = heatmap_model.predict(img)\n",
        "\n",
        "heatmap = np.mean(heatmap_activations, axis=-1)\n"
      ],
      "metadata": {
        "id": "WAb1jZfPGW3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "heatmap = cv2.resize(heatmap, (256, 256))\n",
        "heatmap = cv2.normalize(heatmap, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8UC1)\n",
        "if heatmap.ndim > 2:\n",
        "    heatmap = cv2.split(heatmap)[0]  # select one channel\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "#heatmap = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
        "\n",
        "result = cv2.addWeighted(cv2.cvtColor(np.uint8(255*img[0]), cv2.COLOR_RGB2BGR), 0.5, heatmap, 0.5, 0)"
      ],
      "metadata": {
        "id": "9gwyi8SVG_uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(result)\n",
        "cv2.waitKey(0)"
      ],
      "metadata": {
        "id": "ieIfn73fKTHX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}